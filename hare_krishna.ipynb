{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShwetaRoy17/GC-LFF/blob/main/hare_krishna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0E93WTpN6eh"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VOGpg4_gmvBx"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHyu6Ba3K2C3"
      },
      "outputs": [],
      "source": [
        "import random, time, psutil, threading, csv\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers, layers\n",
        "\n",
        "from keras.api.layers import Dense\n",
        "from keras.api.models import Sequential, load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from scipy.stats import entropy, ttest_rel, wilcoxon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMD_sGeD5gKk"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99G2Ohz9JnK4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9SjpVuoN50D"
      },
      "outputs": [],
      "source": [
        "aqi_df = pd.read_csv('/content/drive/MyDrive/city/city_hour.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbTvq_Z8DRbz"
      },
      "outputs": [],
      "source": [
        "# content\n",
        "# aqi_df = pd.read_csv('/content/city_hour.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo7PwGGvOCpf"
      },
      "outputs": [],
      "source": [
        "# Label Encoding for \"City\"\n",
        "label_encoder = LabelEncoder()\n",
        "aqi_df['city'] = label_encoder.fit_transform(aqi_df['City'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93mqIQW7OgTT"
      },
      "outputs": [],
      "source": [
        "# Create a mapping dictionary\n",
        "city_mapping = dict(zip( label_encoder.transform(label_encoder.classes_),label_encoder.classes_))\n",
        "\n",
        "# Output the mapping\n",
        "print(\"City Mapping:\", city_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6cVdjcGWOiFD"
      },
      "outputs": [],
      "source": [
        "aqi_df.drop(columns=['City'], inplace=True)\n",
        "aqi_df.drop(columns=['AQI_Bucket'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "w6FxxFZmOilH"
      },
      "outputs": [],
      "source": [
        "# Calculate missing values\n",
        "missing_values_count = aqi_df.isnull().sum()\n",
        "total_rows = len(aqi_df)\n",
        "# Create a DataFrame to display missing values information\n",
        "missing_data_table = pd.DataFrame({\n",
        "    \"Feature Name\": missing_values_count.index,\n",
        "    \"Missing Values Count\": missing_values_count.values,\n",
        "    \"Percentage of Missing Data\": (missing_values_count.values / total_rows) * 100\n",
        "}).sort_values(by=\"Percentage of Missing Data\", ascending=False)\n",
        "\n",
        "\n",
        "missing_data_table\n",
        "# Save the table to a CSV file for further analysis\n",
        "# missing_data_table.to_csv('missing_data_summary.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlVWmAazPNTF"
      },
      "source": [
        "# Data prepocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuivsqguKygl"
      },
      "outputs": [],
      "source": [
        "# Feature scaling\n",
        "# scaler = MinMaxScaler()\n",
        "# data_scaled = pd.DataFrame(scaler.fit_transform(data.drop(columns=['Date', 'city'])),\n",
        "#                            columns=data.columns.drop(['Date', 'city']))\n",
        "# data_scaled['city'] = data['city']\n",
        "# data_scaled['Date'] = data['Date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pUc6OjJKygl"
      },
      "outputs": [],
      "source": [
        "aqi_df['date'] = pd.to_datetime(aqi_df['Datetime'])\n",
        "aqi_df['month'] = aqi_df['date'].dt.month\n",
        "aqi_df['year'] = aqi_df['date'].dt.year\n",
        "aqi_df['day_of_week'] = aqi_df['date'].dt.dayofweek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCIE1ZZMKygl"
      },
      "outputs": [],
      "source": [
        "aqi_df.drop(columns=['Datetime'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Kx2ZVjmKygl"
      },
      "outputs": [],
      "source": [
        "# Split city-wise data\n",
        "cities = aqi_df['city'].unique()\n",
        "print(cities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2viokC_RKygl"
      },
      "outputs": [],
      "source": [
        "# city_data = {city: data_scaled[data_scaled['city'] == city].drop(columns=['city', 'date']) for city in cities}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kcaPI7WWKygl"
      },
      "outputs": [],
      "source": [
        "# print(city_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IX5xspbqKygl"
      },
      "outputs": [],
      "source": [
        "aqi_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_ZLL2BM6AAp"
      },
      "source": [
        "# Missing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFbnTLGe6BvU"
      },
      "outputs": [],
      "source": [
        "cols = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2',\n",
        "        'O3', 'Benzene', 'Toluene', 'Xylene', 'AQI']\n",
        "\n",
        "# For final training, use the full dataset (which already contains missing values)\n",
        "data_incomplete = aqi_df[cols].copy()\n",
        "\n",
        "# For hyperparameter tuning, extract complete rows only\n",
        "data_complete = aqi_df[cols].dropna().copy()\n",
        "print(\"Total complete cases for tuning:\", data_complete.shape[0])\n",
        "\n",
        "# Function to artificially introduce missingness on a complete dataset.\n",
        "def introduce_missingness(data, missing_rate=0.2, random_state=42):\n",
        "    np.random.seed(random_state)\n",
        "    data_missing = data.copy().values\n",
        "    mask = np.random.rand(*data_missing.shape) < missing_rate  # True indicates missing\n",
        "    data_missing[mask] = np.nan\n",
        "    return data_missing, mask\n",
        "\n",
        "# Create artificially masked data from the complete subset\n",
        "data_complete_missing, mask_complete = introduce_missingness(data_complete, missing_rate=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZDKOUVV6GLs"
      },
      "source": [
        "# Splitting Data for hypertuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtSW9Koc6JKD"
      },
      "outputs": [],
      "source": [
        "train_data, val_data, train_missing, val_missing, train_mask, val_mask = train_test_split(\n",
        "    data_complete.values, data_complete_missing, mask_complete, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96DLIR6W6NjU"
      },
      "source": [
        "# Evaluation Metric Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqiw2xzn6QeB"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(true, imputed, missing_mask):\n",
        "    # Evaluate only on positions that were artificially masked (where missing_mask is True)\n",
        "    mse = mean_squared_error(true[missing_mask], imputed[missing_mask])\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    # Compute KL divergence per feature using histogram estimates\n",
        "    kl_divs = []\n",
        "    for col in range(true.shape[1]):\n",
        "        true_vals = true[missing_mask[:, col], col]\n",
        "        imputed_vals = imputed[missing_mask[:, col], col]\n",
        "        if true_vals.size == 0 or imputed_vals.size == 0:\n",
        "            continue\n",
        "        true_hist, _ = np.histogram(true_vals, bins=50, density=True)\n",
        "        imputed_hist, _ = np.histogram(imputed_vals, bins=50, density=True)\n",
        "        true_hist += 1e-8\n",
        "        imputed_hist += 1e-8\n",
        "        kl = entropy(true_hist, imputed_hist)\n",
        "        kl_divs.append(kl)\n",
        "    kl_div = np.mean(kl_divs) if kl_divs else np.nan\n",
        "    return mse, rmse, kl_div"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo2fujns6Uqh"
      },
      "source": [
        "# GAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7n_jQh36UI6"
      },
      "outputs": [],
      "source": [
        "class GAIN:\n",
        "    def __init__(self, data_miss, hint_rate=0.9, alpha=100, batch_size=256, epochs=1000, learning_rate=1e-3):\n",
        "        \"\"\"\n",
        "        data_miss: numpy array with missing values as np.nan\n",
        "        hint_rate: probability of providing hint information\n",
        "        alpha: weight for the reconstruction loss\n",
        "        batch_size: training batch size\n",
        "        epochs: number of training epochs\n",
        "        learning_rate: learning rate for optimizers\n",
        "        \"\"\"\n",
        "        self.data_miss = data_miss\n",
        "        self.hint_rate = hint_rate\n",
        "        self.alpha = alpha\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_samples, self.dim = data_miss.shape\n",
        "\n",
        "        # Normalize data feature-wise to [0, 1]\n",
        "        self.min_val = np.nanmin(data_miss, axis=0)\n",
        "        self.max_val = np.nanmax(data_miss, axis=0)\n",
        "        self.norm_data = (data_miss - self.min_val) / (self.max_val - self.min_val + 1e-8)\n",
        "        self.mask = (~np.isnan(data_miss)).astype(np.float32)\n",
        "        self.norm_data = np.nan_to_num(self.norm_data, 0)\n",
        "\n",
        "    def build_generator(self):\n",
        "        inputs = layers.Input(shape=(self.dim*2,))\n",
        "        h = layers.Dense(128, activation='relu')(inputs)\n",
        "        h = layers.Dense(128, activation='relu')(h)\n",
        "        out = layers.Dense(self.dim, activation='sigmoid')(h)\n",
        "        model = tf.keras.models.Model(inputs, out)\n",
        "        return model\n",
        "\n",
        "    def build_discriminator(self):\n",
        "        inputs = layers.Input(shape=(self.dim*2,))\n",
        "        h = layers.Dense(128, activation='relu')(inputs)\n",
        "        h = layers.Dense(128, activation='relu')(h)\n",
        "        out = layers.Dense(self.dim, activation='sigmoid')(h)\n",
        "        model = tf.keras.models.Model(inputs, out)\n",
        "        return model\n",
        "\n",
        "    def train(self, verbose=False):\n",
        "        X = self.norm_data.astype(np.float32)\n",
        "        M = self.mask.astype(np.float32)\n",
        "\n",
        "        # Build generator and discriminator models\n",
        "        generator = self.build_generator()\n",
        "        discriminator = self.build_discriminator()\n",
        "\n",
        "        G_optimizer = optimizers.Adam(self.learning_rate)\n",
        "        D_optimizer = optimizers.Adam(self.learning_rate)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(self.epochs):\n",
        "            # Sample a batch with replacement\n",
        "            idx = np.random.choice(self.n_samples, self.batch_size, replace=True)\n",
        "            X_batch = X[idx]\n",
        "            M_batch = M[idx]\n",
        "\n",
        "            # Add small random noise for missing entries\n",
        "            Z = np.random.uniform(0, 0.01, size=[self.batch_size, self.dim]).astype(np.float32)\n",
        "            X_batch_noisy = X_batch * M_batch + Z * (1 - M_batch)\n",
        "\n",
        "            # Create a hint matrix\n",
        "            H_batch = (np.random.uniform(0, 1, size=[self.batch_size, self.dim]) < self.hint_rate).astype(np.float32)\n",
        "            H_batch = M_batch * H_batch\n",
        "\n",
        "            # --- Train Generator ---\n",
        "            with tf.GradientTape() as tape:\n",
        "                G_input = tf.concat([X_batch_noisy, M_batch], axis=1)\n",
        "                G_sample = generator(G_input)\n",
        "                X_hat = X_batch * M_batch + G_sample * (1 - M_batch)\n",
        "                D_input_for_G = tf.concat([X_hat, H_batch], axis=1)\n",
        "                D_prob = discriminator(D_input_for_G)\n",
        "                # Loss: adversarial loss on missing entries plus weighted reconstruction loss on observed entries\n",
        "                G_loss_adv = -tf.reduce_mean((1 - M_batch) * tf.math.log(D_prob + 1e-8))\n",
        "                mse_loss = tf.reduce_mean((M_batch * X_batch - M_batch * G_sample)**2) / (tf.reduce_mean(M_batch) + 1e-8)\n",
        "                G_loss = G_loss_adv + self.alpha * mse_loss\n",
        "\n",
        "            G_gradients = tape.gradient(G_loss, generator.trainable_variables)\n",
        "            G_optimizer.apply_gradients(zip(G_gradients, generator.trainable_variables))\n",
        "\n",
        "            # --- Train Discriminator ---\n",
        "            with tf.GradientTape() as tape:\n",
        "                G_input = tf.concat([X_batch_noisy, M_batch], axis=1)\n",
        "                G_sample = generator(G_input)\n",
        "                X_hat = X_batch * M_batch + G_sample * (1 - M_batch)\n",
        "                D_input = tf.concat([X_hat, H_batch], axis=1)\n",
        "                D_prob = discriminator(D_input)\n",
        "                D_loss = -tf.reduce_mean(M_batch * tf.math.log(D_prob + 1e-8) + (1 - M_batch) * tf.math.log(1 - D_prob + 1e-8))\n",
        "\n",
        "            D_gradients = tape.gradient(D_loss, discriminator.trainable_variables)\n",
        "            D_optimizer.apply_gradients(zip(D_gradients, discriminator.trainable_variables))\n",
        "\n",
        "            if verbose and epoch % 100 == 0:\n",
        "                print(f\"Epoch {epoch} | G_loss: {G_loss.numpy():.4f} | D_loss: {D_loss.numpy():.4f}\")\n",
        "\n",
        "        # After training, impute missing values for the whole dataset\n",
        "        X_tensor = tf.convert_to_tensor(X)\n",
        "        M_tensor = tf.convert_to_tensor(M)\n",
        "        G_input_full = tf.concat([X_tensor, M_tensor], axis=1)\n",
        "        G_sample_full = generator(G_input_full)\n",
        "        X_imputed_norm = X * M + G_sample_full.numpy() * (1 - M)\n",
        "        X_imputed = X_imputed_norm * (self.max_val - self.min_val + 1e-8) + self.min_val\n",
        "        return X_imputed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M978Wilm6a4b"
      },
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiY3I0av6dwh"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter grid\n",
        "alpha_list = [50, 100, 150, 200, 250]\n",
        "hint_rate_list = [0.8, 0.9, 0.95]\n",
        "learning_rate_list = [1e-3, 5e-4, 1e-4]\n",
        "batch_size_list = [128, 256]\n",
        "tune_epochs = 500  # fewer epochs for tuning\n",
        "\n",
        "results = []\n",
        "best_rmse = np.inf\n",
        "# best_params = {}\n",
        "best_params = {'alpha': 200, 'hint_rate': 0.8, 'learning_rate': 0.0005, 'batch_size': 256, 'epochs': 500}\n",
        "\n",
        "# For reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Loop over hyperparameters\n",
        "# for alpha in alpha_list:\n",
        "#     for hint_rate in hint_rate_list:\n",
        "#         for lr in learning_rate_list:\n",
        "#             for batch_size in batch_size_list:\n",
        "#                 print(f\"Training with alpha={alpha}, hint_rate={hint_rate}, lr={lr}, batch_size={batch_size}\")\n",
        "#                 # Train on training split\n",
        "#                 gain_model_train = GAIN(train_missing, hint_rate=hint_rate, alpha=alpha,\n",
        "#                                           batch_size=batch_size, epochs=tune_epochs, learning_rate=lr)\n",
        "#                 train_imputed = gain_model_train.train(verbose=False)\n",
        "#                 # Evaluate on validation split\n",
        "#                 gain_model_val = GAIN(val_missing, hint_rate=hint_rate, alpha=alpha,\n",
        "#                                         batch_size=batch_size, epochs=tune_epochs, learning_rate=lr)\n",
        "#                 val_imputed = gain_model_val.train(verbose=False)\n",
        "\n",
        "#                 # Compute RMSE on the validation missing entries\n",
        "#                 mse_val, rmse_val, kl_val = compute_metrics(val_data, val_imputed, val_mask)\n",
        "#                 print(f\"--> Validation RMSE: {rmse_val:.4f}\")\n",
        "#                 results.append({\n",
        "#                     'alpha': alpha,\n",
        "#                     'hint_rate': hint_rate,\n",
        "#                     'learning_rate': lr,\n",
        "#                     'batch_size': batch_size,\n",
        "#                     'rmse': rmse_val,\n",
        "#                     'mse': mse_val,\n",
        "#                     'kl': kl_val\n",
        "#                 })\n",
        "#                 if rmse_val < best_rmse:\n",
        "#                     best_rmse = rmse_val\n",
        "#                     best_params = {\n",
        "#                         'alpha': alpha,\n",
        "#                         'hint_rate': hint_rate,\n",
        "#                         'learning_rate': lr,\n",
        "#                         'batch_size': batch_size,\n",
        "#                         'epochs': tune_epochs\n",
        "#                     }\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "print(\"Best Validation RMSE:\", best_rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MmoPAkh6h6b"
      },
      "source": [
        "# Final Training on full dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsPVBaLvXQRW"
      },
      "outputs": [],
      "source": [
        "aqi_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEouq_yZ6hpg"
      },
      "outputs": [],
      "source": [
        "# Increase epochs for final training (if desired)\n",
        "final_epochs = 2000\n",
        "gain_final = GAIN(data_incomplete.values, hint_rate=best_params['hint_rate'],\n",
        "                  alpha=best_params['alpha'], batch_size=best_params['batch_size'],\n",
        "                  epochs=final_epochs, learning_rate=best_params['learning_rate'])\n",
        "data_imputed_final = gain_final.train(verbose=True)\n",
        "data_imputed_final_df = pd.DataFrame(data_imputed_final, columns=cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izs4V4okY7VL"
      },
      "outputs": [],
      "source": [
        "complete_aqi_df = aqi_df.copy()\n",
        "complete_aqi_df[cols] = complete_aqi_df[cols].fillna(data_imputed_final_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzsS2-4q6pnZ"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ghH-hhVq6pWd"
      },
      "outputs": [],
      "source": [
        "# col_to_plot = random.choice(cols)\n",
        "# col_index = cols.index(col_to_plot)\n",
        "\n",
        "# Identify missing indices using the artificial mask\n",
        "# missing_indices = np.where(mask_complete[:, col_index])[0]\n",
        "\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# plt.plot(data_complete.index, data_complete[col_to_plot].values, label='Original', alpha=0.7)\n",
        "# plt.plot(data_complete.index[missing_indices],\n",
        "#          data_imputed_final_df.loc[missing_indices, col_to_plot],\n",
        "#          color='blue', label='GAN Imputed', linewidth=2, zorder=5)\n",
        "# plt.xlabel(\"Index\")\n",
        "# plt.ylabel(col_to_plot)\n",
        "# plt.title(f\"Original vs GAN Imputed Values for {col_to_plot}\")\n",
        "# plt.legend()\n",
        "# plt.grid(True, linestyle='--', alpha=0.6)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wieS1EilNwfO"
      },
      "source": [
        "# Plot of Missing Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VHlO62JNwGv"
      },
      "outputs": [],
      "source": [
        "# List of features to compare\n",
        "features = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx']\n",
        "\n",
        "# Create subplots for each feature\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, feature in enumerate(features):\n",
        "    plt.subplot(3, 2, i+1)\n",
        "\n",
        "    # Plot the original complete data for the feature as a line plot\n",
        "    plt.plot(data_complete.index, data_complete[feature].values, label='Original',\n",
        "             color='blue', alpha=0.7)\n",
        "\n",
        "    # Identify the indices where artificial missingness was introduced for this feature\n",
        "    feature_idx = cols.index(feature)\n",
        "    missing_idx = np.where(mask_complete[:, feature_idx])[0]\n",
        "\n",
        "    # Plot the imputed values from the final imputed DataFrame as a line plot\n",
        "    plt.plot(data_complete.index[missing_idx],\n",
        "             data_imputed_final_df.loc[data_complete.index[missing_idx], feature],\n",
        "             label='GAIN Imputed', color='red', alpha=0.7)\n",
        "\n",
        "    plt.title(f\"{feature}: Original vs GAIN Imputed\")\n",
        "    plt.xlabel(\"Index\")\n",
        "    plt.ylabel(feature)\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrV_xKurOnYO"
      },
      "source": [
        "# Comparison with Tradtional Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ1N9KyEPtxc"
      },
      "outputs": [],
      "source": [
        "# Mean Imputation\n",
        "mean_imputer = SimpleImputer(strategy='mean')\n",
        "data_mean = pd.DataFrame(mean_imputer.fit_transform(data_complete_missing), columns=cols)\n",
        "\n",
        "# KNN Imputation\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "data_knn = pd.DataFrame(knn_imputer.fit_transform(data_complete_missing), columns=cols)\n",
        "\n",
        "# MICE Imputation (IterativeImputer)\n",
        "mice_imputer = IterativeImputer(random_state=0)\n",
        "data_mice = pd.DataFrame(mice_imputer.fit_transform(data_complete_missing), columns=cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rm1FAdczbGbg"
      },
      "outputs": [],
      "source": [
        "# Increase epochs for final training (if desired)\n",
        "final_epochs = 2000\n",
        "gain_final = GAIN(data_complete_missing, hint_rate=best_params['hint_rate'],\n",
        "                  alpha=best_params['alpha'], batch_size=best_params['batch_size'],\n",
        "                  epochs=final_epochs, learning_rate=best_params['learning_rate'])\n",
        "data_gain_imputed = gain_final.train(verbose=True)\n",
        "data_gain_complete = pd.DataFrame(data_gain_imputed, columns=cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsKA5eNqRgHK"
      },
      "outputs": [],
      "source": [
        "data_substituted = aqi_df.fillna(data_gain_complete)\n",
        "print(data_substituted.shape)\n",
        "print(aqi_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFtNBUdBQBE2"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(true, imputed, missing_mask):\n",
        "    # valid_mask = np.logical_and(missing_mask, ~np.isnan(true))\n",
        "    valid_mask = missing_mask\n",
        "    # Calculate errors only on missing entries (where missing_mask is True)\n",
        "    mse = mean_squared_error(true[valid_mask], imputed[valid_mask])\n",
        "    rmse = np.sqrt(mse)\n",
        "    # Compute KL divergence per feature (using histogram estimates)\n",
        "    kl_divs = []\n",
        "    for col in range(true.shape[1]):\n",
        "        true_hist, _ = np.histogram(true[valid_mask[:, col], col], bins=50, density=True)\n",
        "        imputed_hist, _ = np.histogram(imputed[valid_mask[:, col], col], bins=50, density=True)\n",
        "        true_hist += 1e-8\n",
        "        imputed_hist += 1e-8\n",
        "        kl = entropy(true_hist, imputed_hist)\n",
        "        kl_divs.append(kl)\n",
        "    kl_div = np.mean(kl_divs)\n",
        "    return mse, rmse, kl_div\n",
        "\n",
        "# Ground truth (complete data) as numpy array\n",
        "true_data = data_complete.values\n",
        "\n",
        "# Compute metrics for each imputation method\n",
        "mse_mean, rmse_mean, kl_mean = compute_metrics(true_data, data_mean.values, mask_complete)\n",
        "mse_knn, rmse_knn, kl_knn = compute_metrics(true_data, data_knn.values, mask_complete)\n",
        "mse_mice, rmse_mice, kl_mice = compute_metrics(true_data, data_mice.values, mask_complete)\n",
        "mse_gain, rmse_gain, kl_gain = compute_metrics(true_data, data_gain_imputed, mask_complete)\n",
        "\n",
        "print(\"Mean Imputation  - MSE: {:.4f}, RMSE: {:.4f}, KL Divergence: {:.4f}\".format(mse_mean, rmse_mean, kl_mean))\n",
        "print(\"KNN Imputation   - MSE: {:.4f}, RMSE: {:.4f}, KL Divergence: {:.4f}\".format(mse_knn, rmse_knn, kl_knn))\n",
        "print(\"MICE Imputation  - MSE: {:.4f}, RMSE: {:.4f}, KL Divergence: {:.4f}\".format(mse_mice, rmse_mice, kl_mice))\n",
        "print(\"GAIN Imputation  - MSE: {:.4f}, RMSE: {:.4f}, KL Divergence: {:.4f}\".format(mse_gain, rmse_gain, kl_gain))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bCDobMuRHFW"
      },
      "outputs": [],
      "source": [
        "def get_error_vector(true, imputed, missing_mask):\n",
        "    # Compute squared errors per entry and then average per sample (only for missing entries)\n",
        "    errors = (true - imputed)**2\n",
        "    # For each sample, take the mean error over features where the value was missing.\n",
        "    sample_errors = np.array([np.nanmean(errors[i][missing_mask[i]]) for i in range(true.shape[0])])\n",
        "    return sample_errors\n",
        "\n",
        "error_mean = get_error_vector(true_data, data_mean.values, mask_complete)\n",
        "error_knn  = get_error_vector(true_data, data_knn.values, mask_complete)\n",
        "error_mice = get_error_vector(true_data, data_mice.values, mask_complete)\n",
        "error_gain = get_error_vector(true_data, data_gain_imputed.values, mask_complete)\n",
        "\n",
        "# Remove samples where there were no missing entries (if any)\n",
        "valid_idx = ~np.isnan(error_gain)\n",
        "error_mean = error_mean[valid_idx]\n",
        "error_knn  = error_knn[valid_idx]\n",
        "error_mice = error_mice[valid_idx]\n",
        "error_gain = error_gain[valid_idx]\n",
        "\n",
        "# Paired t-tests: comparing GAIN with each method\n",
        "ttest_mean = ttest_rel(error_gain, error_mean)\n",
        "ttest_knn  = ttest_rel(error_gain, error_knn)\n",
        "ttest_mice = ttest_rel(error_gain, error_mice)\n",
        "\n",
        "print(\"T-test (GAIN vs Mean)  | Statistic: {:.4f}, p-value: {:.4f}\".format(ttest_mean.statistic, ttest_mean.pvalue))\n",
        "print(\"T-test (GAIN vs KNN)   | Statistic: {:.4f}, p-value: {:.4f}\".format(ttest_knn.statistic, ttest_knn.pvalue))\n",
        "print(\"T-test (GAIN vs MICE)  | Statistic: {:.4f}, p-value: {:.4f}\".format(ttest_mice.statistic, ttest_mice.pvalue))\n",
        "\n",
        "# Wilcoxon signed-rank tests\n",
        "wilcox_mean = wilcoxon(error_gain, error_mean)\n",
        "wilcox_knn  = wilcoxon(error_gain, error_knn)\n",
        "wilcox_mice = wilcoxon(error_gain, error_mice)\n",
        "\n",
        "print(\"Wilcoxon (GAIN vs Mean)  | Statistic: {:.4f}, p-value: {:.4f}\".format(wilcox_mean.statistic, wilcox_mean.pvalue))\n",
        "print(\"Wilcoxon (GAIN vs KNN)   | Statistic: {:.4f}, p-value: {:.4f}\".format(wilcox_knn.statistic, wilcox_knn.pvalue))\n",
        "print(\"Wilcoxon (GAIN vs MICE)  | Statistic: {:.4f}, p-value: {:.4f}\".format(wilcox_mice.statistic, wilcox_mice.pvalue))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIK-7PED4Kpb"
      },
      "source": [
        "#  Federated Learning Pre-req"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xv7Z-Rke4Nq-"
      },
      "outputs": [],
      "source": [
        "#CNN-LSTM model\n",
        "# --- Step 3: Prepare Data for Federated Learning ---\n",
        "def create_model(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv1D(64, 3, activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Conv1D(64, 3, activation='relu'),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.LSTM(64, activation='relu', return_sequences=True),\n",
        "        layers.LSTM(32, activation='tanh'),\n",
        "        layers.Dense(10, activation='relu'),\n",
        "        layers.Dense(1)  # Predict AQI\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDGXLX3143Xq"
      },
      "outputs": [],
      "source": [
        "# --- Helper function to create time-series windows ---\n",
        "def create_time_series(df, window_size=10):\n",
        "    # Exclude the 'AQI' column from the features\n",
        "    feature_cols = df.columns.drop('AQI')\n",
        "    data_features = df[feature_cols].values\n",
        "    # Use the AQI column as the target\n",
        "    data_target = df['AQI'].values\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(df) - window_size):\n",
        "        X.append(data_features[i:i+window_size, :])\n",
        "        y.append(data_target[i+window_size])\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm-TujfsEgF9"
      },
      "source": [
        "# Preprocessing Citywise data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "L5mtZfO4Eimn"
      },
      "outputs": [],
      "source": [
        "nodes_data = {}\n",
        "nodes_test_data = {}\n",
        "window_size = 15\n",
        "\n",
        "for city in complete_aqi_df['city'].unique():\n",
        "    city_df = complete_aqi_df[complete_aqi_df['city'] == city][cols]\n",
        "    X, y = create_time_series(city_df, window_size=window_size)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "    nodes_data[city] = (X_train, y_train)\n",
        "    nodes_test_data[city] = (X_test, y_test)\n",
        "    print(f\"City {city} - Train Samples: {len(X_train)}, Test Samples: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2BkB9DNZUM7"
      },
      "source": [
        "# FL: Error Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vEAroMXoEvKR"
      },
      "outputs": [],
      "source": [
        "# --- Evaluation ---\n",
        "mse_list, rmse_list, mae_list, r2_list, rmsle_list = [], [], [], [], []\n",
        "city_metrics = {}\n",
        "\n",
        "def rmsle(y_true, y_pred):\n",
        "    # Adding 1 to avoid log(0) and ensure positive values\n",
        "    return np.sqrt(np.mean((np.log(y_pred + 1) - np.log(y_true + 1))**2))\n",
        "\n",
        "print(\"\\n--- Final Evaluation ---\")\n",
        "for city, (X_test, y_test) in nodes_test_data.items():\n",
        "    preds = global_model.predict(X_test, verbose=0).flatten()\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    rmsle_val = rmsle(y_test, preds)\n",
        "\n",
        "    mse_list.append(mse)\n",
        "    rmse_list.append(rmse)\n",
        "    mae_list.append(mae)\n",
        "    r2_list.append(r2)\n",
        "    rmsle_list.append(rmsle_val)\n",
        "\n",
        "    city_metrics[city] = {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2, 'RMSLE': rmsle_val}\n",
        "    print(f\"{city} => MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, RMSLE: {rmsle_val:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BcOTZm9_-8a"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "nodes_data = {}\n",
        "nodes_val_data = {}\n",
        "nodes_test_data = {}\n",
        "window_size = 15\n",
        "\n",
        "# Create train/val/test splits per city\n",
        "for city in complete_aqi_df['city'].unique():\n",
        "    city_df = complete_aqi_df[complete_aqi_df['city'] == city][cols]\n",
        "    X, y = create_time_series(city_df, window_size=window_size)\n",
        "\n",
        "    # Split: 60% train, 20% val, 20% test\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, shuffle=False)\n",
        "\n",
        "    nodes_data[city] = (X_train, y_train)\n",
        "    nodes_val_data[city] = (X_val, y_val)\n",
        "    nodes_test_data[city] = (X_test, y_test)\n",
        "\n",
        "    print(f\"City {city} - Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V78l2TnNJPpL"
      },
      "source": [
        "# NEW FL CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQTjyfCAAexs",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# --- Federated Learning ---\n",
        "num_rounds = 10\n",
        "local_epochs = 1\n",
        "batch_size = 32\n",
        "example_city = list(nodes_data.keys())[0]\n",
        "global_input_shape = nodes_data[example_city][0].shape[1:]\n",
        "\n",
        "global_model = create_model(global_input_shape)\n",
        "global_weights = global_model.get_weights()\n",
        "training_time_record = {}\n",
        "\n",
        "max_times = []\n",
        "\n",
        "for rnd in range(num_rounds):\n",
        "    print(f\"\\n--- Federated Round {rnd+1} ---\")\n",
        "    local_weights = []\n",
        "    round_training_times = {}\n",
        "\n",
        "    for city in nodes_data:\n",
        "        X_train, y_train = nodes_data[city]\n",
        "\n",
        "        local_model = create_model(global_input_shape)\n",
        "        local_model.set_weights(global_weights)\n",
        "\n",
        "        start_time = time.time()\n",
        "        local_model.fit(X_train, y_train, epochs=local_epochs, batch_size=batch_size, verbose=0)\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        round_training_times[city] = elapsed_time\n",
        "        local_weights.append((len(X_train), local_model.get_weights()))\n",
        "\n",
        "        print(f\"City {city}: Samples = {len(X_train)}, Time = {elapsed_time:.2f} sec\")\n",
        "\n",
        "    training_time_record[rnd+1] = round_training_times\n",
        "\n",
        "    round_max = max(round_training_times.values())\n",
        "    max_times.append(round_max)\n",
        "\n",
        "    # Weighted FedAvg\n",
        "    total_samples = sum([n for n, _ in local_weights])\n",
        "    new_global_weights = []\n",
        "    for weights_per_layer in zip(*[w[1] for w in local_weights]):\n",
        "        weighted_avg = np.sum([n / total_samples * w for (n, w) in zip([n for n, _ in local_weights], weights_per_layer)], axis=0)\n",
        "        new_global_weights.append(weighted_avg)\n",
        "    global_weights = new_global_weights\n",
        "\n",
        "global_model.set_weights(global_weights)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_times = [14.653037548065186,\n",
        " 13.506239414215088,\n",
        " 9.634636878967285,\n",
        " 15.834002494812012,\n",
        " 17.275151014328003,\n",
        " 9.323030710220337,\n",
        " 8.875787496566772,\n",
        " 21.47063636779785,\n",
        " 8.884452104568481,\n",
        " 22.44563364982605]"
      ],
      "metadata": {
        "id": "8e2juQsQ2F4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzmhK3NBM8p5"
      },
      "outputs": [],
      "source": [
        "# --- Personalized Fine-Tuning ---\n",
        "print(\"\\n--- Personalized Fine-Tuning Phase ---\")\n",
        "personalized_models = {}\n",
        "personalized_results = {}\n",
        "personalized_times = {}\n",
        "\n",
        "for city in nodes_data:\n",
        "    X_train, y_train = nodes_data[city]\n",
        "    X_val, y_val = nodes_val_data[city]\n",
        "    X_test, y_test = nodes_test_data[city]\n",
        "\n",
        "    personal_model = create_model(global_input_shape)\n",
        "    personal_model.set_weights(global_weights)\n",
        "\n",
        "    # Combine train + val for fine-tuning\n",
        "    X_personal = np.concatenate([X_train, X_val], axis=0)\n",
        "    y_personal = np.concatenate([y_train, y_val], axis=0)\n",
        "\n",
        "    start_time = time.time()\n",
        "    personal_model.fit(X_personal, y_personal, epochs=3, batch_size=batch_size, verbose=0)\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    test_loss,test_mse, test_mae = personal_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print()\n",
        "\n",
        "    personalized_models[city] = personal_model\n",
        "    personalized_results[city] = {\n",
        "        \"loss\": test_loss,\n",
        "        \"mae\": test_mae,\n",
        "        \"time\": elapsed_time\n",
        "    }\n",
        "    personalized_times[city] = elapsed_time\n",
        "\n",
        "    print(f\"City {city}: Personalized Test Loss = {test_loss:.4f}, MAE = {test_mae:.4f}, Fine-tune Time = {elapsed_time:.2f} sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0XIXk3QAJNK"
      },
      "outputs": [],
      "source": [
        "# --- Personalized Model Evaluation ---\n",
        "personal_mse_list, personal_rmse_list, personal_mae_list = [], [], []\n",
        "personal_r2_list, personal_rmsle_list = [], []\n",
        "personalized_city_metrics = {}\n",
        "\n",
        "def rmsle(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true))**2))\n",
        "\n",
        "print(\"\\n--- Personalized Model Evaluation ---\")\n",
        "for city in nodes_test_data:\n",
        "    X_test, y_test = nodes_test_data[city]\n",
        "    model = personalized_models[city]\n",
        "    preds = model.predict(X_test, verbose=0).flatten()\n",
        "\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    rmsle_val = rmsle(y_test, preds)\n",
        "\n",
        "    personal_mse_list.append(mse)\n",
        "    personal_rmse_list.append(rmse)\n",
        "    personal_mae_list.append(mae)\n",
        "    personal_r2_list.append(r2)\n",
        "    personal_rmsle_list.append(rmsle_val)\n",
        "\n",
        "    personalized_city_metrics[city] = {\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'R2': r2,\n",
        "        'RMSLE': rmsle_val,\n",
        "        'FineTuneTime': personalized_results[city]['time']\n",
        "    }\n",
        "\n",
        "    print(f\"{city} => MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, RMSLE: {rmsle_val:.4f}, Time: {personalized_results[city]['time']:.2f} sec\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69AlyyliZXoN"
      },
      "source": [
        "# FL: Error Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0oyE4-XXA8h"
      },
      "outputs": [],
      "source": [
        "# --- Confidence Intervals / Error Bars ---\n",
        "def summary_stat(metric_list, name):\n",
        "    mean_val = np.mean(metric_list)\n",
        "    std_val = np.std(metric_list)\n",
        "    print(f\"\\n{name} Mean: {mean_val:.4f}, Std: {std_val:.4f}\")\n",
        "    return mean_val, std_val\n",
        "\n",
        "mean_mse, std_mse = summary_stat(personal_mse_list, \"MSE\")\n",
        "mean_rmse, std_rmse = summary_stat(personal_rmse_list, \"RMSE\")\n",
        "mean_mae, std_mae = summary_stat(personal_mae_list, \"MAE\")\n",
        "\n",
        "# --- Visualization with Error Bars ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "cities = list(personalized_city_metrics.keys())\n",
        "mse_vals = [personalized_city_metrics[c]['MSE'] for c in cities]\n",
        "rmse_vals = [personalized_city_metrics[c]['RMSE'] for c in cities]\n",
        "mae_vals = [personalized_city_metrics[c]['MAE'] for c in cities]\n",
        "\n",
        "x = np.arange(len(cities))\n",
        "width = 0.25\n",
        "\n",
        "plt.bar(x - width, mse_vals, width, label='MSE')\n",
        "plt.bar(x, rmse_vals, width, label='RMSE')\n",
        "plt.bar(x + width, mae_vals, width, label='MAE')\n",
        "plt.xticks(x, cities, rotation=45)\n",
        "plt.ylabel(\"Error\")\n",
        "plt.title(\"Model Performance by City\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSJDJE3pE03X"
      },
      "outputs": [],
      "source": [
        "# --- Confidence Intervals / Error Bars ---\n",
        "def summary_stat(metric_list, name):\n",
        "    mean_val = np.mean(metric_list)\n",
        "    std_val = np.std(metric_list)\n",
        "    print(f\"\\n{name} Mean: {mean_val:.4f}, Std: {std_val:.4f}\")\n",
        "    return mean_val, std_val\n",
        "\n",
        "mean_mse, std_mse = summary_stat(mse_list, \"MSE\")\n",
        "mean_rmse, std_rmse = summary_stat(rmse_list, \"RMSE\")\n",
        "mean_mae, std_mae = summary_stat(mae_list, \"MAE\")\n",
        "\n",
        "# --- Visualization with Error Bars ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "cities = list(city_metrics.keys())\n",
        "mse_vals = [city_metrics[c]['MSE'] for c in cities]\n",
        "rmse_vals = [city_metrics[c]['RMSE'] for c in cities]\n",
        "mae_vals = [city_metrics[c]['MAE'] for c in cities]\n",
        "\n",
        "x = np.arange(len(cities))\n",
        "width = 0.25\n",
        "\n",
        "plt.bar(x - width, mse_vals, width, label='MSE')\n",
        "plt.bar(x, rmse_vals, width, label='RMSE')\n",
        "plt.bar(x + width, mae_vals, width, label='MAE')\n",
        "plt.xticks(x, cities, rotation=45)\n",
        "plt.ylabel(\"Error\")\n",
        "plt.title(\"Model Performance by City\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qzX5TIwlKWqt"
      },
      "outputs": [],
      "source": [
        "def plot_prediction_vs_actual(city_name, y_true, y_pred, num_points=100):\n",
        "    \"\"\"\n",
        "    Plots the predicted vs actual AQI values for a given city.\n",
        "\n",
        "    Args:\n",
        "        city_name (str): Name of the city.\n",
        "        y_true (np.array): Ground truth AQI values.\n",
        "        y_pred (np.array): Predicted AQI values.\n",
        "        num_points (int): Number of data points to show (default: 100).\n",
        "    \"\"\"\n",
        "    # Limit the number of points plotted for readability\n",
        "    y_true = y_true[:num_points]\n",
        "    y_pred = y_pred[:num_points]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(y_true, label='Actual AQI', marker='o')\n",
        "    plt.plot(y_pred, label='Predicted AQI', marker='x')\n",
        "    plt.title(f\"AQI Prediction vs Actual - {city_mapping[city_name]}\")\n",
        "    plt.xlabel(\"Time Step\")\n",
        "    plt.ylabel(\"AQI\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "cities=[2,10,12,14,18,19,20,25]\n",
        "\n",
        "for city in range(25):\n",
        "  # Get test data for the city\n",
        "  X_test, y_test = nodes_test_data[city]\n",
        "\n",
        "  # Predict using the final global model\n",
        "  y_pred = global_model.predict(X_test).flatten()\n",
        "\n",
        "  # Call the function to visualize predictions with error bars\n",
        "  plot_prediction_vs_actual(city_name=city, y_true=y_test, y_pred=y_pred, num_points=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npUZnafxE3EA"
      },
      "outputs": [],
      "source": [
        "# --- Training Time Output ---\n",
        "print(\"\\nTraining Time Summary:\")\n",
        "for round_num, times in training_time_record.items():\n",
        "    print(f\"Round {round_num}: {times}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkQliV5N5Eif"
      },
      "source": [
        "# Centralized Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HMPS34DHYpPb"
      },
      "outputs": [],
      "source": [
        "# --- Centralized Learning (Corrected) ---\n",
        "\n",
        "# Create time series data from the centralized (complete) dataset\n",
        "# Use the same window size as before and the preprocessed features in 'cols'\n",
        "window_size = 15\n",
        "X, y = create_time_series(complete_aqi_df[cols], window_size=window_size)\n",
        "\n",
        "# Optionally, you could split X and y into train/test sets.\n",
        "# Here we use the full dataset for demonstration.\n",
        "print(\"Centralized Data Shape:\", X.shape, y.shape)\n",
        "\n",
        "# Create the model using the same architecture\n",
        "model = create_model(input_shape=X.shape[1:])\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the model (adjust epochs as needed)\n",
        "# model.fit(X, y, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# 1) Prepare to collect times\n",
        "# run_times = [1083.4012246131897, 1087.9414508342743, 1084.7454762458801, 1055.643892288208, 974.6234679222107, 987.1062573756184, 976.25, 980.28, 983.14, 973.76]\n",
        "\n",
        "# run_times = [983.14, 1055.643892288208, 973.76, 1084.7454762458801,\n",
        "#  976.25, 1087.9414508342743, 987.1062573756184, 980.28,\n",
        "#  974.6234679222107, 1083.4012246131897]\n",
        "\n",
        "\n",
        "# 2) Repeat fit 10×\n",
        "for run in range(10 - len(run_times)):\n",
        "    print(f\"\\n--- Centralized Run {run} ---\")\n",
        "    start = time.time()\n",
        "    model.fit(X, y, epochs=10, batch_size=32, verbose=1)\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    print(f\"Run {run} time: {elapsed:.2f} sec\")\n",
        "    run_times.append(elapsed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_times = [983.14, 1055.643892288208, 973.76, 1084.7454762458801,\n",
        " 976.25, 1087.9414508342743, 987.1062573756184, 980.28,\n",
        " 974.6234679222107, 1083.4012246131897]\n"
      ],
      "metadata": {
        "id": "VZ1MS9Eeez9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_times"
      ],
      "metadata": {
        "id": "p_f5NQVKfHga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your two timing lists\n",
        "fl_times = max_times        # e.g. [t1, t2, …, t10]\n",
        "cl_times = run_times        # e.g. [t1', t2', …, t10']\n",
        "\n",
        "# x‐axes (1→10)\n",
        "rounds = list(range(1, len(fl_times) + 1))\n",
        "runs   = list(range(1, len(cl_times) + 1))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(rounds, fl_times, marker='o', label='Federated Learning')\n",
        "plt.plot(runs,   cl_times, marker='s', label='Centralized Learning')\n",
        "plt.xlabel('Iteration (Round)')\n",
        "plt.ylabel('Training Time (sec)')\n",
        "plt.title('FL vs. CL: Training Time Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8HDYxEMDdfLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m6YBX0vrzMy"
      },
      "source": [
        "# CL vs FL city wise prediction graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Dpk-mAPCr6R6"
      },
      "outputs": [],
      "source": [
        "for city in nodes_test_data:\n",
        "    city_name = city_mapping[city]\n",
        "\n",
        "    # --- FL Predictions ---\n",
        "    X_test, y_test = nodes_test_data[city]\n",
        "    fl_model = personalized_models[city]\n",
        "    fl_preds = fl_model.predict(X_test, verbose=0).flatten()\n",
        "\n",
        "    # --- Centralized Predictions ---\n",
        "    # Filter the complete dataset for the current city.\n",
        "    city_df = complete_aqi_df[complete_aqi_df['city'] == city][cols]\n",
        "    # Create time-series data for the city.\n",
        "    X_cent, y_cent = create_time_series(city_df, window_size=window_size)\n",
        "    cent_preds = model.predict(X_cent, batch_size=32, verbose=0).flatten()\n",
        "\n",
        "    # --- Align the Curves ---\n",
        "    # It is likely that the lengths of the FL test set and the CL test set differ.\n",
        "    # We take the minimum length among original values and predictions from both models.\n",
        "    common_len = min(len(y_test), len(fl_preds), len(y_cent), len(cent_preds))\n",
        "    y_test_common = y_test[:common_len]\n",
        "    fl_preds_common = fl_preds[:common_len]\n",
        "    y_cent_common = y_cent[:common_len]\n",
        "    cent_preds_common = cent_preds[:common_len]\n",
        "\n",
        "    # Optionally, if you believe y_test and y_cent represent the same underlying AQI,\n",
        "    # you can choose one as the \"Original\" curve. Here, we use y_test_common.\n",
        "\n",
        "    # --- Plotting ---\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(np.arange(common_len), y_test_common, label='Original AQI',\n",
        "             color='blue', linestyle='-')\n",
        "    plt.plot(np.arange(common_len), fl_preds_common, label='FL Prediction',\n",
        "             color='red', linestyle='--')\n",
        "    plt.plot(np.arange(common_len), cent_preds_common, label='CL Prediction',\n",
        "             color='green', linestyle='-.')\n",
        "    plt.xlabel(\"Test Sample Index\")\n",
        "    plt.ylabel(\"AQI\")\n",
        "    plt.title(f\"Prediction Comparison for City {city_name}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntJ-TGj2vAYp"
      },
      "outputs": [],
      "source": [
        "for city_idx in cities:\n",
        "    # Choose a city (using the first city as an example)\n",
        "    city = list(nodes_test_data.keys())[city_idx]\n",
        "    city_name = city_mapping[city]\n",
        "    X_test, y_test = nodes_test_data[city]\n",
        "\n",
        "    # Get predictions from the personalized FL model\n",
        "    fl_model = personalized_models[city]\n",
        "    fl_preds = fl_model.predict(X_test, verbose=0).flatten()\n",
        "\n",
        "    # Get predictions from the centralized model on the same test set\n",
        "    # Here we assume that centralized model predictions can be obtained on X_test directly.\n",
        "    # (If the centralized model uses a different windowing, you should ensure the comparison is on identical test samples.)\n",
        "    cent_preds = model.predict(X_test, batch_size=32, verbose=0).flatten()\n",
        "\n",
        "    # Compute the squared error for each sample for both models\n",
        "    error_fl = (y_test - fl_preds)**2\n",
        "    error_cl = (y_test - cent_preds)**2\n",
        "\n",
        "    # Perform paired t-test to compare the errors\n",
        "    t_stat, p_value = ttest_rel(error_fl, error_cl)\n",
        "\n",
        "    print(f\"City {city_name} - Paired t-test comparing FL and CL errors:\")\n",
        "    print(f\"t-statistic: {t_stat:.4f}, p-value: {p_value:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "j0E93WTpN6eh",
        "vMD_sGeD5gKk",
        "A_ZLL2BM6AAp",
        "wieS1EilNwfO"
      ],
      "gpuType": "V28",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}